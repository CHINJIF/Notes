{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOSQL 综述\n",
    "\n",
    "### 特点\n",
    "* 分布式集群\n",
    "* 一个产品一般都很有针对性，有其对应的应由场景\n",
    "\n",
    "### 核心技术\n",
    "* 存储引擎\n",
    "  * 行存储\n",
    "  * 列存储\n",
    "  * 内存数据库\n",
    "* 索引设计\n",
    "  * b+树\n",
    "  * 位图\n",
    "* sql优化器\n",
    "* 事务管理与并发控制\n",
    "  * 锁\n",
    "* 容错和恢复\n",
    "\n",
    "### 数据存储\n",
    "#### OLTP VS OLAP \n",
    " 数据处理大致可以分成两大类：联机事务处理OLTP（on-line transaction processing）、联机分析处理OLAP（On-Line Analytical Processing）\n",
    "* OLTP: On-line transaction processing\n",
    "  * 也叫联机事务处理，表示事务性非常高的系统，一般都是高可用的在线系统，以小的事务以及小的查询为主\n",
    "  * OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。\n",
    "* OLAP: One-line Analytical procesing\n",
    "  * OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。 \n",
    "  * OLAP中可以大量使用位图索引，物化视图，对于大的事务，尽量寻求速度上的优化，没有必要像OLTP要求快速提交，甚至要刻意减慢执行的速度。\n",
    "  \n",
    "\n",
    "#### 行式存储\n",
    "* 数据文件基本组成：块／页\n",
    "* 缺点，如果需要按列筛选，每一行所有数据都需要读内存\n",
    "\n",
    "#### 列式存储\n",
    "* 按列存在块里\n",
    "* OLAP\n",
    "\n",
    "#### 内存数据库\n",
    "* 数据小\n",
    "* 全部载入内存\n",
    "* timesten，altibase，soliddb\n",
    "* 内存索引可以用哈希，外存用b+树\n",
    "\n",
    "#### 关系型数据库弱点\n",
    "* 难分布式，因为要不停的join\n",
    "* 依赖于强大的服务器，贵，hard to scale\n",
    "* 难以处理非结构化数据，列都要预先定义好\n",
    "\n",
    "#### 参考书\n",
    "nosql 数据库入门\n",
    "\n",
    "### CAP定理\n",
    "* consistency -- 一致性 ACID，通常牺牲consistency\n",
    "* availability -- 可用性\n",
    "* patition tolerance - 分区容忍性，一部分分区坏掉，还是可以用\n",
    "* cap 只能满足其二\n",
    "\n",
    "#### 只能满足其二\n",
    "* ca: rational db\n",
    "* cp: mongodb\n",
    "* ap: dynamo, cassandro\n",
    "\n",
    "### 分类\n",
    "* key-value 键值数据库:  dynamo, cassandra, riak, voldemort, redis\n",
    "  * join 变成一系列key-value查询\n",
    "  * groupby\n",
    "* 面向文档的数据库，mongodb\n",
    "  * 处理非结构化数据厉害\n",
    "* 面向列的数据库， hbase，google bigtable\n",
    "* 面向图的数据库， neo4j\n",
    "\n",
    "### 产品\n",
    "#### redis\n",
    "* 支持丰富的数据类型：数组，链表，集合\n",
    "\n",
    "#### big table\n",
    "##### example\n",
    "* 学生表需要存，s(s#, snumber, sdepartment, sa)\n",
    "* 所有的数据都放放在一个大表里\n",
    "\n",
    "#### mongodb\n",
    "* 面向文档，所谓文档其实就是一行，但是每一行列是不固定的，为了和行这个概念区分，叫文档\n",
    "\n",
    "#### new sql\n",
    "* 关系数据化nosql\n",
    "* nosql上面包装一个sql解析器--sql外壳\n",
    "* voltdb\n",
    "   * OLTP, SQL, 分布式集群，内存数据库\n",
    "\n",
    "## memcached\n",
    "* 键值存储，基于内存\n",
    "* 可以在内存中做为数据库的缓存，介于应用层和数据库之间\n",
    "* 可以设置数据过期时间，来解决cache更新\n",
    "\n",
    "### 特点\n",
    "* 全内存运转，关机后数据丢失\n",
    "* lru算法导致数据不可控的丢失\n",
    "* 应用场景有限，主要作为数据库缓存\n",
    "* 哈希方式存储\n",
    "* 简单文本协议进行数据通信\n",
    "* 只操作字符型数据，只是字节流\n",
    "* 其他类型数据由应用解释，不支持复杂的数据类型，全部依靠应用程序来解释类型，应用端厚，服务器没有多少东西，不负责序列化及反序列化\n",
    "* 集群采用一致性散列（哈希）算法\n",
    "\n",
    "### install\n",
    "* yum install memcached\n",
    "\n",
    "### start\n",
    "* cd /etc/rc.d/init.d\n",
    "* ./memcached start\n",
    "* memcached -d -p 11212   // start memcached at port 11212 and run in backend\n",
    "\n",
    "### telnet 测试\n",
    "* telnet localhost 11211\n",
    "\n",
    "```\n",
    "set a_key 0 10 3\n",
    "a_value\n",
    "\n",
    "get a_key\n",
    "\n",
    "delete a_key\n",
    "\n",
    "```\n",
    "\n",
    "#### rubygems\n",
    "* ruby memcached-client\n",
    "* could store value for number, string, array, dictionary\n",
    "\n",
    "\n",
    "#### more memcached nodes\n",
    "* 多个拷贝，可以启动多个memcached\n",
    "* 保证一致性 - 一致性哈希\n",
    "\n",
    "### 一致性哈希\n",
    "* memcached node i 负责管理 keys 满足： hash（key) % n == i\n",
    "* 假设一共四个节点，那么key： abc 会落到 hash（\"abc\") % 4 = 2, 2好节点\n",
    "\n",
    "* 如果一个节点 i 失效，那么所有cache 该 i管的，给i+1\n",
    "* 如果增加一个节点，i，i-1分一半的key给它\n",
    "\n",
    "##### hash function\n",
    "* crc32 冗余校验算法\n",
    "* 计算hash值很快，甚至可以在硬件里直接算\n",
    "\n",
    "##### memcached 一致性\n",
    "\n",
    "\n",
    "\n",
    "#### 高可用方案\n",
    "* 首先，假设有4个节点，一个down掉，那么25% cache会失效，会造成数据库访问25%的波动\n",
    "* 高可用方案通过提供replic 保证如果一个节点failed 还有另一个一样的节点，来接管\n",
    "* repcached\n",
    "\n",
    "```\n",
    "repcached -p 11211 -x localhost -v -d \n",
    "```\n",
    "* 对端口11211监听，刚才memcached在那个端口启用，对那个端口的写会自动写到repcached，如果那个端口有失败，那么repcached立即采取行动\n",
    "* 在应用里如果发现一个端口down，那么可以程序控制来读repcached里的\n",
    "\n",
    "###### spark storm 也都是基于内存的存贮\n",
    "\n",
    "\n",
    "## redis\n",
    "* 是memcached一种改进\n",
    "* 键值数据库\n",
    "* c实现\n",
    "* 稳定性高\n",
    "\n",
    "#### 特点\n",
    "* 内存 + 磁盘的持久化保存\n",
    "* 具有丰富的数据类型\n",
    "* 自带master slave复制\n",
    "* 数据快照\n",
    "\n",
    "#### 支持的数据类型\n",
    "* string\n",
    "* 链表\n",
    "* 集合\n",
    "* 有序集合\n",
    "* 散列表\n",
    "\n",
    "#### 场景\n",
    "* 时间线应用，e.g 微博，\n",
    "* 对数组有频繁的添加和删除\n",
    "\n",
    "#### install\n",
    "* yum install redis\n",
    "\n",
    "#### config\n",
    "* daemonize yes    // 是不是后台运行\n",
    "* port 6379\n",
    "* bind 127.0.0.1\n",
    "* timeout 0       ／／ i seconds 没有client链接 自动关掉\n",
    "* dir  数据快照写入的目录\n",
    "* save sec      决定多少次变更之后，把数据写入磁盘持久化\n",
    "\n",
    "#### op\n",
    "```\n",
    "set a_key 4     // 4 字节数\n",
    "a_value\n",
    "\n",
    "get a_key\n",
    "\n",
    "setex foo 5 3    // 3 sec 后过期\n",
    "```\n",
    "\n",
    "#### 储存链表\n",
    "```\n",
    "lpush data 3\n",
    "foo\n",
    "\n",
    "lpush data 3\n",
    "bar\n",
    "\n",
    "lrange data 0 -1   // check linked list from head to tail\n",
    "```\n",
    "\n",
    "#### 有向集合\n",
    "```\n",
    "zadd sets 1 4\n",
    "hoge\n",
    "\n",
    "zadd sets 2 4\n",
    "fuga\n",
    "\n",
    "zrange sets 0 -1\n",
    "```\n",
    "\n",
    "### master slave 复制\n",
    "* 在redis-server 的配置文件里把该server 配制成某master ip／port的slave\n",
    "* slave of localhost\n",
    "\n",
    "* 在master push的数据，在slave里自动复制\n",
    "\n",
    "#### start\n",
    "* redis-server config_file\n",
    "\n",
    "#### 集群管理\n",
    "* 哈希一致性算法 来管理redis 集群 节点，类似于memcached 多进程\n",
    "* shard -- 多redis master\n",
    "* replic／slave -- 多备份\n",
    "* redis里面没有中心节点，没有central failure，hadoop 的namenode 就有\n",
    "\n",
    "### redis 数据类型操作与应用\n",
    "* redis-cli 命令行客户端\n",
    "\n",
    "#### 场景1 计数器\n",
    "* 论坛帖子点击数，点击量会造成大量的数据库读写\n",
    "\n",
    "```\n",
    "> redis-cli -p 6379\n",
    "\n",
    "set visits:1:totals 21389     //more key compose keys, 1 means page 1\n",
    "set visits:2:totals 13243242\n",
    "\n",
    "incr visits:342:totals    // increase totals\n",
    "get visits:342:totals\n",
    "```\n",
    "\n",
    "#### 场景2 非结构化数据\n",
    "hset, hget, hincrby  用于操作哈希表，便于存储非结构化数据，e.g 如果每个user带有的属性不同，用redis非常方便\n",
    "```\n",
    "hset users:jdoe name \"john doe\"\n",
    "hset users:jdoe email \"xxx@cc.com\"\n",
    "hset users:jdoe phone \"343342342\"\n",
    "\n",
    "hincrby users:jdoe visits 1    // increse by visits by 1\n",
    "\n",
    "hget users:jdoe email\n",
    "\n",
    "hgetall users:jdoe\n",
    "\n",
    "hkyes user:jdoe\n",
    "\n",
    "hvalue user:jdoe\n",
    "```\n",
    "\n",
    "#### 场景3 集合，用集合保存社交网站圈子数据\n",
    "* 那些网站，属于一个圈子，circle\n",
    "```\n",
    "sadd circle:jdoe:family users:mike\n",
    "sadd circle:jdoe:family users:pite\n",
    "\n",
    "sadd circile:jdoe:soccer users:brade\n",
    "\n",
    "smembers circle:jdoe:family\n",
    "\n",
    "sinter circle:jdoe:family circle:jdoe:soccer   // 求交集\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query for keys\n",
    "\n",
    "```\n",
    "keys h*llo\n",
    "keys h?llo\n",
    "keys h[ae]llo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 场景4 QATH 协议\n",
    "skip\n",
    "\n",
    "##### 数据模型设计 一个应用 - for OATH 协议\n",
    "数据：\n",
    "\n",
    "* consumer keys   加密的密钥\n",
    "* consumer secrets        lksdlfkdsj\n",
    "* request tokens 签名\n",
    "* access tokens\n",
    "* nonces   登陆的随机码\n",
    "\n",
    "服务器代码：\n",
    "```\n",
    "hgetall  /consumers/key:lksdlfkdsj     // 验证这个用户\n",
    "sadd  /nonces/key:lksdlfkdsj/timestamp:20192039238    //验证随机码\n",
    "hset  /request_tokens/key:lksdlfkdsj  ksloiefsjkl ksjdfiejoj  //给key建立一个token\n",
    "\n",
    "set /authorizations/request_token:ksloiefsjkl\n",
    "```\n",
    "\n",
    "#### 场景5 倒排索引\n",
    "* 文章分词，去掉stop word之后 做倒排索引 inverted index \n",
    "* word, [(document_id, offset，word_count), (document_id， offset, word_count)] \n",
    "```\n",
    "//分词后 文章剩下的关键字有 finance, bloomberg, issue\n",
    "sinter words:finance words:bloomberg word:issue  // 求所有词出现的交集就好 \n",
    "```\n",
    "\n",
    "### redis 持久化\n",
    "* 快照 (snapshot)：作为备份。设定触发条件，发生则把内存里的数据，写入数据库的snapshot文件，e.g. 写入了>100文件。系统奔溃以后，重启会把快照的东西载入内存。会造成数据丢失, 上一次备份，崩溃之间的数据会丢失 .rdb\n",
    "* AOF (Append Only File)：所有改写数据操作都会写入日志，崩溃，日志重新运行所有命令 .aof\n",
    "\n",
    "#### 快照\n",
    "CONFIG\n",
    "```\n",
    "save 300 10  // 每10秒钟 有300次修改\n",
    "dbfilename dump.rdb    // 快照文件 文件名\n",
    "```\n",
    "\n",
    "##### 快照原理\n",
    "* 生成快照时，当前进程fork出一个子进程，写入rdb文件\n",
    "* 会受到内存大小的限制，容易造成内存/redis的崩溃\n",
    "* master/slave 也是借助快照文件传递数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AOF\n",
    "```\n",
    "appendonly yes   //enable  AOF\n",
    "```\n",
    "* AOF 优先于 RDB\n",
    "* RDB 性能优于 AOF，不会重复更新一条数据\n",
    "* AOF rewrite, 合并重复aof文件 去掉重复\n",
    "\n",
    "#### VM\n",
    "* 为了解决数据库大小受内存限制\n",
    "* redis不会将全部数据装入内存，把热value放入内存，冷数据放在磁盘\n",
    "* 但是因为操作系统本身就会做VM优化，所以这个功能其实有重复，后续版本去掉\n",
    "\n",
    "##### redis 会有的问题\n",
    "* 快照会引发的问题\n",
    "  * 写快照，把数据从load back from 快照，会产生很多io，造成阻塞\n",
    "  * 解决方法：采用master/slave，永远不要再master上设置快照！ 在slave上设置，那么master不会崩溃\n",
    "* 主从复制阻塞\n",
    "  * 解决： skip\n",
    "  \n",
    "## Mongodb -- 文档数据库\n",
    "* 基本概念\n",
    "* 数据类型和数据模型\n",
    "* 分布式：主从复制\n",
    "* 分片\n",
    "* 管理维护：快照，备份\n",
    "* 应用案例\n",
    "\n",
    "#### 基本概念\n",
    "* C++ 编写， 支持Linux，windows，solaris \n",
    "* 主要针对**非结构化数据**，对列无限制\n",
    "* 全面的索引支持，可以在任意属性上建立索引. 没有列结构，但是还是能基于列做索引\n",
    "* 支持map/reduce\n",
    "* 高可用\n",
    "\n",
    "#### 构成\n",
    "##### 文档\n",
    "* 文档是一个区别于表格，行/列的概念\n",
    "* 无法固定模式/模型，数据结构持续变化的无法被结构化的一条数据，是一个文档\n",
    "```\n",
    "{\"foo\":3, \"greating\": \"Hello, world!\"},   // 一行就是一个文档\n",
    "{\"Foo\":3},                                // 支持数值，字符串, case sensitive\n",
    "{\"greating\":\"Hello world\", \"greating\": \"Hello, mongoDB!\"} // 一个文档中列不能重复\n",
    "```\n",
    "**文档也可以嵌套，利用文档嵌套可以做链接**\n",
    "\n",
    "##### 集合\n",
    "* 集合是一组文档，对应于SQL中的表\n",
    "* 集合是无模式的\n",
    "\n",
    "##### 数据库\n",
    "* 由多个集合组成\n",
    "* 数据库名必须全小写\n",
    "\n",
    "#### 安装和配置\n",
    "* /etc/mongod.conf\n",
    "  * fork: 子进程\n",
    "  * port: 27017\n",
    "  * dbfilepath : 数据库文件存放\n",
    "* mogod -f /etc/mongod.conf\n",
    "\n",
    "##### 支持的数据类型\n",
    "* null\n",
    "* float ...\n",
    "* regx\n",
    "* array： {\"messages\": []}, {\"a_array\": {1, 2, 3}}\n",
    "* undefine\n",
    "* binaray\n",
    "* object id: 12字节，0-3字节 时间戳， 4-6字节 机器表示， 7-8字节pid， 9-11字节计数器； 系统缺省function产生\n",
    "* 文档嵌套：\n",
    "  * {\"response\": {\"landmarkss\": [**{\"Name\": \"tiananmen\"}**]}   // name也是一个文档\n",
    "\n",
    "#### op\n",
    "##### insert 文档\n",
    "* 检查文档是否有_id, 没有指定_id\n",
    "* 检查数据大小>16Mb, 大于则不能处理\n",
    "* 批量插入，检查少，速度比sql数据库快\n",
    "\n",
    "```\n",
    "> db.foo.insert({\"bar\": \"baz\"}\n",
    "> db.foo.find()\n",
    "> {\"_id\": ObjectId(\"2314532fjoi328797313uj4h87\"), \"bar\": \"baz\"}     系统自动生成id\n",
    "```\n",
    "\n",
    "#### 删除文档\n",
    "```\n",
    "> db.foo.remove()\n",
    "> db.foo.remove({\"bar\":\"baz\"})\n",
    "```\n",
    "\n",
    "#### upsert模式\n",
    "* 如果找到记录更新， 没找到增加\n",
    "```\n",
    "> db.users.update((\"name\": \"joe\"), joe, true, true)\n",
    "```\n",
    "\n",
    "#### multi模式\n",
    "* skip\n",
    "\n",
    "#### 参考书\n",
    "* mongodb权威指南\n",
    "* 深入学习mongodb\n",
    "\n",
    "25\n",
    "\n",
    "## Cassandra -- 键值数据库\n",
    "\n",
    "## HBASE\n",
    "* hadoop database\n",
    "* 分布式，面向列的数据库，来源于google bigtable\n",
    "* 日志及数据数据库， 插入和删除都是增加数据+时间戳，不会删除数据而是加一个删除标签\n",
    "* 基于HDFS, hadoop filesystem\n",
    "\n",
    "\n",
    "### big table\n",
    "* 所有的数据都可以用三个东西表示：\n",
    "  * 行键\n",
    "  * 属性\n",
    "  * 值\n",
    "* 所以所有数据都可以放到一个表里\n",
    "* bigtable里如果做groupby很麻烦，但是如果是做基于key，value的查询，则很快\n",
    "* bigtable的**join**，可以通过chain key-value queries来实现\n",
    "\n",
    "#### HBASE 逻辑视图\n",
    "|行键|时间戳|列族 限定符(列名) contents|列族 anchor| \n",
    "|---|---|----|----|\n",
    "|\"com.cnn.www\"|18||anchor:my.look.ca=\"CNN\"|\n",
    "|\"com.cnn.www\"|16|contents:data=\"IBM\"||\n",
    "|\"com.cnn.www\"|15|contents:data=\"IBM\"||\n",
    "\n",
    "* 插入，是对同样的key追加一条新数据，时间戳不一样\n",
    "* 删除，也是追加一条新数据，有删除标记\n",
    "\n",
    "###### 构成\n",
    "* 最基本单位：列\n",
    "* 多列 => 列族\n",
    "* 多列/列族 => 行\n",
    "* 多行 => 表\n",
    "\n",
    "\n",
    "###### 列族\n",
    "* 列的表示<列族>:<限定符>  family:qualifier\n",
    "* 列族实际上是对列分组，因为逻辑里，一些概念会需要一起访问/修改，e.g security， 把对应security的列放在一起，称他们为一个列族。逻辑放在一起，物理存储在一起。\n",
    "  * 同样的列族 存储在一样的物理存储里，对应一个 Hreigon -> Store(HFile)\n",
    "  * 一个列族的所有列存储在同一个底层的存储文件里，这个存储文件叫做 **HFile**\n",
    "  * 那么一行有可能分布在不同的物理Store里\n",
    "\n",
    "\n",
    "\n",
    "##### 行键\n",
    "* 访问行的方式\n",
    "  * 单个行键\n",
    "  * 给定行键范围： partial key\n",
    "  * 全表扫描： scan\n",
    "\n",
    "#### 时间戳\n",
    "* 可以基于时间戳expire数据\n",
    "* 用于版本控制\n",
    "\n",
    "#### HBASE 物理模型\n",
    "![HBASE Architecture](img/hbase_architecture.png)\n",
    "\n",
    "* HMaster： 总控节点\n",
    "* HRegion：一个物理设备\n",
    "* Store：一个列族存在一个Store里\n",
    "* memstore： 内存\n",
    "* storefile：持久化外存\n",
    "\n",
    "* HFile 本身又是分布式的，不同的HFile会被分不到不同的DFS节点\n",
    "\n",
    "##### Region\n",
    "* 行最开始都存在一个region里\n",
    "* 数据增长后，会被分区到不同的region\n",
    "\n",
    "##### 系统表\n",
    "* meta\n",
    "  * 记录表的region的信息，某个key去哪个region找\n",
    "  * meta 表也可能跨region\n",
    "* root\n",
    "  * root记录meta表怎么对应region\n",
    "  * root只能有一个，不跨region\n",
    "  \n",
    "**三级查找，就能找到 root->meta->region**, zookeeper负责这些通信管理\n",
    "\n",
    "##### memstore 和 storefile\n",
    "* 新数据先写入memstore\n",
    "* 达到阈值之后，写入storefile\n",
    "* storefile存不下了，分布式，分布到不同的region\n",
    "\n",
    "### HBASE VS Oracle\n",
    "* 索引不同\n",
    "* Hbase 适用于大量插入同时又读写的情况\n",
    "* Hbase的瓶颈是硬盘传输速度，oracle的瓶颈是硬盘寻道时间(很受限)\n",
    "* Oracle all-in-one\n",
    "* Hbase支持的功能不如oracle，sql的很多groupby etc\n",
    "* HBASE 只支持key-value查询，索引只能针对key\n",
    "\n",
    "HBASE 是不停的写，插入和删除都是写一条新数据，就是往数据库批量并行写数据\n",
    "\n",
    "#### 行式vs列式\n",
    "* 行式数据库是按行存\n",
    "  * 对于列的检索，e.g 统计country 列包含哪些国家\n",
    "  * 需要把全部所有行，>GB,TB 数据载入内存，筛选出需要的一列 country\n",
    "* 列式数据就是按列族存\n",
    "* 同一列的元素一般很相似，很容易压缩，e.g 如果只有0/1 按位压缩\n",
    "* 对于OLTP 类型事务，因为对ACID 要求很高，事务性很强，反而行式会好用的多\n",
    "\n",
    "#### 索引\n",
    "* HBASE 也用 b+树\n",
    "* 称为LSM索引\n",
    "  * LSM tree： \n",
    "\n",
    "### OP\n",
    "#### 表操作\n",
    "```\n",
    "> create 'member', 'member_id', 'address', 'info'\n",
    "> list                            // 列出所有的表\n",
    "> describe 'member'              // 表的信息\n",
    "> exists 'member'                // 看表存在否\n",
    "> is_enabled 'member'             // 看表是否在线\n",
    "\n",
    "> alter 'member', {NAME=>'member_id', METHOD=>'delete'}   //删除列\n",
    "```\n",
    "\n",
    "#### 插入记录\n",
    "```\n",
    "put 'member', 'scutshuxue', 'info:age', '24'              // 新建了一列 age\n",
    "put 'member', 'scutshuxue', 'info:birthday', '1987-06-17'\n",
    "```\n",
    "\n",
    "**数据类型只支持字符型**\n",
    "\n",
    "#### 查询记录\n",
    "```\n",
    "get 'member', 'scutshuxue'\n",
    "get 'member', 'scutshuxue', 'info'     //只查询某个列族\n",
    "get 'member', 'scutshuxue', 'info:age'  \n",
    "scan 'memeber'     //扫描\n",
    "```\n",
    "\n",
    "#### 删除更新\n",
    "```\n",
    "delete  'member', 'scutshuxue', 'info'\n",
    "deleteall 'member', 'scutshuxue'\n",
    "```\n",
    "\n",
    "\n",
    "### 模式设计和场景应用\n",
    "##### 什么场景试用\n",
    "* 成熟的数据分析主题，查询模式已经确立且不轻易改变\n",
    "* 适合海量的，但是简单的操作(key-value)\n",
    "* 适合高速插入，大量读取\n",
    "\n",
    "### 辅助索引\n",
    "* HBASE 不能在列上面做secendary index, 辅助索引\n",
    "* 辅助表\n",
    "* 复合行键：userid-messageid, 用两个key，符合成一个key，让查询更灵活\n",
    "#### 参考书\n",
    "HBASE 权威指南 CH1 CH8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
