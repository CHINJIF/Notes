{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. 系统架构\n",
    "#### 系统架构演化\n",
    "* 垂直架构：MVC，一个大而全的项目，放在一个服务器里\n",
    "* RPC：远程过程调用，把不同的部分，业务逻辑，数据存储拆分到不同的服务器，通过网络远程协议调用\n",
    "    * 缺点：这些过程没有中心化管理，很难监控和管理\n",
    "        * 协议栈\n",
    "* SOA: RPC + 服务治理中心\n",
    "* 微服务： 在SOA的基础上，又把服务器虚拟化，拆分到一个功能一个服务。e.g 利用docker\n",
    "![HBASE Map Reduce](img/rpc.png)\n",
    "##### 问题\n",
    "* 这些架构都没有提供高可用性，服务器挂了怎么办？\n",
    "* 提供高可用性，那么意味着一个服务有多个节点提供，怎么调度？怎么把服务挂起？在服务中路由？\n",
    "    * solution：\n",
    "        * 集群\n",
    "        * 负载均衡/反向代理(proxy)： nginx\n",
    "        * 调度算法：random robin，轮询，hash-ip, ...\n",
    "        \n",
    "##### 负载均衡\n",
    "\n",
    "        \n",
    "##### RPC\n",
    "Remote procedure call, 远程服务调用，允许像调用本地服务一样调用远程服务。\n",
    "###### 提供\n",
    "* 通信机制，TCP/UDP\n",
    "* 序列化方式，XML/JSON/二进制\n",
    "* 通信细节\n",
    "\n",
    "###### 不提供\n",
    "* 服务治理\n",
    "* 服务发现\n",
    "* 就是两个进程之间相互调用\n",
    "\n",
    "###### 实现\n",
    "* 基于消息队列系统的实现，Rabbitmq/kafka\n",
    "* 基于java NIO, Apache Thrift\n",
    "* 基于序列化框架的实现，Avro RPC\n",
    "\n",
    "##### SOA\n",
    "* RPC + 服务治理中心\n",
    "* 利用zookeeper来提供治理\n",
    "\n",
    "###### Zookeeper\n",
    "* 调度中心\n",
    "* clients 告诉 zookeeper需要什么服务，自己的地址\n",
    "* zookeeper 查询服务，告诉client， cients自己去找service\n",
    "* 阿里提供dubbo 提供SOA服务治理框架\n",
    "\n",
    "##### zookeeper + dubbo\n",
    "https://www.bilibili.com/video/av27237493/?p=4\n",
    "\n",
    "###### 分布式引发的问题\n",
    "* 分开到不同的服务器 -> 网络通信\n",
    "* 怎么找到需要的服务器地址，**动态寻址**，通信 => 服务的注册和发现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. 网络编程\n",
    "### 2.1 协议\n",
    "* TCP\n",
    "    * 三次握手，四次挥手\n",
    "* HTTP\n",
    "* AMQP\n",
    "* SOAP\n",
    "\n",
    "#### 连接分类\n",
    "* 长连接\n",
    "    * client和server之间一只保持连接，通过心跳检测来保证连接有效\n",
    "* 短连接\n",
    "    * client发完请求，收到回复就断开\n",
    "\n",
    "##### 可靠性保证\n",
    "* 链路有效性检测\n",
    "    * tcp层面的heartbeat检测\n",
    "    * 协议层的heartbeat检测，e.g SMPP proxy\n",
    "    * 应用层的heartbeat检测\n",
    "* 断连重连机制\n",
    "    * 链路失败时，一定要释放资源 handler（句柄）\n",
    "    * client等待一段时间后尝试重新连接，（expenencial backoff）\n",
    "* 消息缓存重发，queue\n",
    "\n",
    "### 2.2 Socket 编程\n",
    "#### 2.2.1 fileno 文件描述符\n",
    "\n",
    "### 2.3 异步编程\n",
    "#### 协程 - 轻量级线程\n",
    "\n",
    "#### 线程\n",
    "\n",
    "#### 进程\n",
    "\n",
    "#### 多机器 - 网络\n",
    "\n",
    "\n",
    "### 2.4 网络通信框架\n",
    "* blocking io/BIO\n",
    "* Not blocking io/NIO\n",
    "* Async IO/AIO\n",
    "\n",
    "### 2.5 负载均衡 load balancing\n",
    "区别是client知不知道地址\n",
    "#### 2.5.0 概念\n",
    "* 正向代理：知道你要去哪儿 vpn， google.com -> go\n",
    "* 反向代理：到了一个中心，不用关心去哪儿，我说要什么服务，中心替我找\n",
    "* session, cookie:\n",
    "    * 两个节点中，session不能共享，很多人喜欢在session中存数据，e.g 登陆验证。在节点中切换中，登陆不停失效\n",
    "    * solution\n",
    "        * A.不要让一个客户的请求在不同的节点中跳转, 依靠调度算法\n",
    "        * B.session共享，session在集群中同步，不推荐, 因为session会占用链接，而每个服务器的请求的数目是有限制的，session共享严重限制了可以处理的请求数。 共享数据要占用一个链接，而且同步还消耗性能，性能反而遍地\n",
    "* 调度算法\n",
    "    * 轮循算法：每个请求就不听跳转 + redis 可以解决\n",
    "    * hash-ip：一致性哈希算法\n",
    "\n",
    "        \n",
    "### 2.6 编码与序列化\n",
    "#### 序列化\n",
    "* parquet\n",
    "* Avro\n",
    "* Thrift\n",
    "* PB\n",
    "* MessagePack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. 分布式解决方案\n",
    "### 3.1 数据一致性\n",
    "#### 3.1.0 原理\n",
    "##### 1) ACID\n",
    "* Atomicity 原子性\n",
    "    * 全部成功执行\n",
    "    * 全部不执行\n",
    "* Consistency 一致性\n",
    "    * 数据强一致性\n",
    "* Isolation 隔离性\n",
    "    * 在并发环境中，事务时相互隔离的，事物间不能相互干扰\n",
    "    * 隔离级别\n",
    "        * Read Uncomitted, 允许dirty read\n",
    "        * Read committed\n",
    "        * Repeatable Read，不允许dirty read\n",
    "        * Serializable，最严格的隔离级别，并发和串行结果完全一样\n",
    "* Durability 持久性\n",
    "    * 事务一旦提交，对数据的变更就是永久的\n",
    "   \n",
    "![HBASE Map Reduce](img/isolation.png) \n",
    "##### 2)  CAP\n",
    "* 一个系统不能同时满足Consistency，Availability and Partition tolerance\n",
    "* 最多只能满足其二\n",
    "* 分区容错性：\n",
    "    * 分布式系统中，在任何网络分区有故障时，仍然能够提供满足一致性和可用性的服务\n",
    "* 三个特性中\n",
    "    * P是必须有的，不然就不是分布式系统啦 \n",
    "    * C可以放弃强一致性，而追求最终一致性\n",
    "    * 架构师往往组要根据业务特点在C和A中间需求平衡\n",
    "    \n",
    "#####  3) BASE\n",
    "* Basically Available 基本可用\n",
    "    * 响应时间的损失\n",
    "    * 功能上的损失\n",
    "    * 在峰值访问量，通过增加时延，和减少额外的功能来换取系统性能\n",
    "* Soft state 软状态\n",
    "    * 允许数据存在中间状态\n",
    "    * 允许不同节点在同步数据副本是存在不一致的状态和延时\n",
    "* Eventually consistent 最终一致性\n",
    "    * 经过一定的时间窗口后，数据一致，不要求实时保证系统的强一致性\n",
    "        * 因果一致性 Causal consistency\n",
    "            * 如果进程A在改变数据后通知进程B，则需要保证，其之后的更新都通知B\n",
    "            * 如果没有这种关系的进程A,C 则不需要\n",
    "        * read your writes\n",
    "        * session consistency\n",
    "            * 同一个session的数据读写，总保持一致\n",
    "        * Monotonic read consistency\n",
    "        * Monotonic write consistency\n",
    "\n",
    "##### 4) 一致性协议\n",
    "* 2PC - 两阶段提交\n",
    "* 3PC - 三阶段提交\n",
    "* Paxos\n",
    "\n",
    "#### 3.1.1 Paxos \n",
    "https://www.bilibili.com/video/av21667358?from=search&seid=2794461600340825245\n",
    "* 其实是一个共识算法\n",
    "* 一致性: S3 等产品保证 100% CP，99.99 A\n",
    "\n",
    "###### 一致性模型\n",
    "* 弱一致性：\n",
    "    * 最终一致性\n",
    "        * DNS\n",
    "        * Gossip (Cassandra的通信协议)\n",
    "* 强一致性\n",
    "    * 同步\n",
    "    * paxos\n",
    "    * raft(multi-paxos)\n",
    "    * ZAB(multi-paxos) -- zookeeper的一致性模型\n",
    "\n",
    "###### 强一致性算法\n",
    "* 主从同步复制\n",
    "    * 主从通过复制保持一致 -- 很难高可用\n",
    "    * 多数派 >n/2 \n",
    "        * 在并发环境下，无法保证正确性\n",
    "    * paxos\n",
    "        * basic paxos\n",
    "        * multi paxos\n",
    "        * fast paxos\n",
    "\n",
    "###### basic paxos\n",
    "* 角色：\n",
    "    * client\n",
    "    * propser：接受client请求，向集群提出propose，冲突发生时调节，像议员\n",
    "    * accpetor(voter): 提议投票和接收者，只有大于majority，提议才会接受，像国会\n",
    "    * learner：提议接受者，backup，对集群一致性没有影响，像记录员\n",
    "    \n",
    "* phases：\n",
    "    1. Prepare\n",
    "    2. Promise\n",
    "    3. Accept\n",
    "    4. Accepted\n",
    "\n",
    "* 问题：\n",
    "    * 难实现\n",
    "    * 效率低\n",
    "    * 活锁\n",
    "        * 如果在一个propose提出时，有另一个propose进来，靠id编号，或者时间取舍最近的\n",
    "        * 那如果两个client不停的发最近的propose来竞争资源，那么就会造成活锁\n",
    "    \n",
    "![HBASE Map Reduce](img/basic_paxos.png)\n",
    "\n",
    "###### 强一致性算法 -- Raft\n",
    "* 划分成三个子问题\n",
    "    * leader election\n",
    "    * log replication\n",
    "    * safety\n",
    "* 重定义角色\n",
    "    * leader\n",
    "    * follower\n",
    "    * candidate\n",
    "\n",
    "#### 3.1.2 Raft\n",
    "\n",
    "### 3.2 服务可用性和分区容错的架构\n",
    "\n",
    "#### 3.2.1 master/slave\n",
    "\n",
    "#### 3.2.2 active/standby\n",
    "\n",
    "#### 3.2.3 leader/follower\n",
    "\n",
    "### 3.3 分布式锁\n",
    "#### 3.3.0 锁\n",
    "* 悲观锁\n",
    "* 乐观锁\n",
    "* 死/活锁\n",
    "* 读/写锁\n",
    "\n",
    "#### 3.3.1 基于Chubby实现\n",
    "\n",
    "#### 3.3.2 基于Zookeeper实现\n",
    "\n",
    "#### 3.3.3 基于redis实现\n",
    "\n",
    "### 3.4 缓存\n",
    "#### 构建LRU Cache\n",
    "\n",
    "#### 构建LFU Cache\n",
    "\n",
    "### 3.5 分布式文件系统\n",
    "* GFS\n",
    "* HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.  消息队列\n",
    "### 4.0 概念\n",
    "#### 信道/channel\n",
    "##### AMQP协议 - RabbitMQ\n",
    "AMQP（高级消息队列协议）是一个异步消息传递所使用应用层协议规范，为面向消息中间件设计，基于此协议的客户端与消息中间件可以无视消息来源传递消息，不受客户端、消息中间件、不同的开发语言环境等条件的限制\n",
    "\n",
    "* 端口：5672\n",
    "* 优点\n",
    "    * TCP 链接非常昂贵，而使用线程操作AMQP，在一个TCP链接中开通多个信道更优\n",
    "    ![HBASE Map Reduce](img/AMQP.png)\n",
    "\n",
    "AMQP当中有四个概念非常重要: 虚拟主机（virtual host），交换机（exchange），队列（queue）和绑定（binding）。一个虚拟主机持有一组交换机、队列和绑定。为什么需要多个虚拟主机呢？很简单，RabbitMQ当中，用户只能在虚拟主机的粒度进行权限控制。因此，如果需要禁止A组访问B组的交换机/队列/绑定，必须为A和B分别创 建一个虚拟主机。每一个RabbitMQ服务器都有一个默认的虚拟主机“/”。\n",
    "\n",
    "Producer 要产生消息必须要创建一个 Exchange ，Exchange 用于转发消息，但是它不会做存储，如果没有 Queue bind 到 Exchange 的话，它会直接丢弃掉 Producer 发送过来的消息，当然如果消息总是发送过去就被直接丢弃那就没有什么意思了，一个 Consumer 想要接受消息的话，就要创建一个 Queue ，并把这个 Queue bind 到指定的 Exchange 上，然后 Exchange 会把消息转发到 Queue 那里，Queue 会负责存储消息，Consumer 可以通过主动 Pop 或者是 Subscribe 之后被动回调的方式来从 Queue 中取得消息。\n",
    "\n",
    "#### 优点\n",
    "* 应用解耦 - decouple \n",
    "    * queue作为客户端和服务器的中间件，使client和server应用解耦\n",
    "* 支持高并发 - High Concurrency\n",
    "    * 流量削峰 实际上就是**消息缓存**，前后端分离。\n",
    "* 提供冗余，queue里的数据支持备份，可恢复\n",
    "* 扩展性\n",
    "* 作为缓冲\n",
    "* 顺序保证\n",
    "* 异步通信\n",
    "    ![HBASE Map Reduce](img/mq_log.png)\n",
    "\n",
    "#### 消息队列模式\n",
    "* 点对点 push-pull\n",
    "    * 缺点，得老有一个进程去pull\n",
    "* 发布/订阅 push-push\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Kafka\n",
    "* Kafka基于发布/订阅模式\n",
    "* 发布订阅系统中会有一个broker，也是发布消息的中心点\n",
    "* scala写的\n",
    "* kafka的集群管理依赖zookeeper，即broker管理\n",
    "* 基于topic管理数据\n",
    "\n",
    "#### 架构\n",
    "* 主要是producer，kafka集群，consumer\n",
    "* 每个kafka的高可用，是leader/follower模式\n",
    "* 和rabbitmq不同，每个consumer有自己的queue，数据实际存在queue中，kafka的数据存在partition里，每个consumer有自己的offset\n",
    "* consumer, kafka集群 之间的交互通过zookeeper实现\n",
    "    * producer不和zookeeper打交道\n",
    "\n",
    "###### topic\n",
    "* 每个消息对应一个topic，每个topic有多个partition\n",
    "* partition，分区用来做每个kafka服务器的负载均衡\n",
    "* 分区在集群中的多个服务器中都有副本，用leader/follower模式\n",
    "    每个partition i 都有自己的leader和follower，副本必须跨服务器\n",
    "\n",
    "###### consumer \n",
    "* consumer group\n",
    "    * 同一个consumer group里的consumer不能消费同一个分区的数据\n",
    "    * 所以他们不会拿到一样的message，可以达到分流的目的\n",
    "\n",
    "### 安装与配置\n",
    "#### 集群\n",
    "\n",
    "* server.properties\n",
    "\n",
    "```shell\n",
    "broker.id=0\n",
    "\n",
    "delete.topc.enable=true\n",
    "\n",
    "log.dirs=/opt/kafka\n",
    "\n",
    "num.partitions=1\n",
    "\n",
    "zookeeper.connet=hadoop102:2181, hadoop103:2181, hadoop104:2181\n",
    "```\n",
    "\n",
    "#### 命令\n",
    "* kafka-topics.sh\n",
    "* kafka-console-consumer.sh\n",
    "* kafka-console-producer.sh\n",
    "\n",
    "\n",
    "```shell\n",
    "# 启动zookeeper\n",
    "zkstart.sh\n",
    "\n",
    "zkstart.sh status\n",
    "\n",
    "# start kafka, 只能单机一台一台启动\n",
    "kafka-server.start.sh config/server.properties\n",
    "\n",
    "# 查看启动的进程\n",
    "jps -l \n",
    "\n",
    "# 创建一个topic，设定需要多少个分区，多少个副本，连接在那个zookeeper端口，名字\n",
    "kafka-topics.sh --create --zookeeper hadoop102:2181 --partitions 2 --replication-facotr 2 --topic firstTopic \n",
    "\n",
    "# 查看topic\n",
    "kafka-topics.sh --list --zookeeper hadoop102:2181 \n",
    "```\n",
    "\n",
    "* produce\n",
    "```\n",
    "```\n",
    "\n",
    "* consume\n",
    "```shell\n",
    "# consumer和zookeeper连接\n",
    "# 每个kafka的offset本来存在broker里，但是这就需要consumer与kafka broker也建立连接，浪费\n",
    "# 新版本的kafka把offset存在zookeeper中\n",
    "kafka-console-consumer.sh --zookeeper hadoop102:2191 --topic firstTopic --from-beginning\n",
    "\n",
    "```\n",
    "![HBASE Map Reduce](img/kafka.png)\n",
    "\n",
    "https://www.jianshu.com/p/d3e963ff8b70\n",
    "\n",
    "\n",
    "https://www.bilibili.com/video/av35354301/?p=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 RabbitMQ\n",
    "6种模式 https://www.bilibili.com/video/av48444262/?p=4\n",
    "\n",
    "https://www.cnblogs.com/diegodu/p/4971586.html\n",
    "\n",
    "* erlang写的\n",
    "\n",
    "#### 4.2.0 原理\n",
    "##### ACK与消息持久化\n",
    "消息应答\n",
    "* auto ack = true：阅后即焚，消息给到消费者了，MQ就立马把消息从内存中删除\n",
    "    * 如果消费者执行中宕机，那么会丢失正在处理中的消息\n",
    "* auto ack = false: 手动模式\n",
    "    * 如果有一个消费者挂掉，MQ发现有消息没有被ACK，则把该消息给其他消费者\n",
    "    * 消费者ACK之后，MQ再把消息从内存中删除\n",
    "\n",
    "**就安全么，内存中的消息，MQ挂掉也就没了，并没有被持久化**\n",
    "* MQ支持消息的持久化\n",
    "    * durable=ture，声明队列的时候可以设置该参数，使消息持久化到磁盘\n",
    "    * 注意声明队列的参数一经设定，不能被修改\n",
    "\n",
    "##### 交换机/转发器，exhange\n",
    "* 用法见4.2.3\n",
    "* 接收producer消息，然后给队列转发\n",
    "* 交换机不能 persistent 消息\n",
    "* type\n",
    "    * exhange = '' 匿名转发\n",
    "* exhange有自己的分发模式\n",
    "    * fanout 不处理路由键\n",
    "        * 只要跟exhange绑定的队列，都能收到消息\n",
    "    * topic 将路由和某种模式绑定\n",
    "    * direct 处理路由键\n",
    "        * routing模式采用该方式\n",
    "        * 发送的时候有一个路由key，队列也有key，如果match才转发\n",
    "    \n",
    "##### 消息确认机制 (事务 + confirm)\n",
    "* 问题：生产者将消息发送到MQ之后，到底有没有到达\n",
    "    * 默认是不知道的，MQ不返回任何信息\n",
    "    * 两种方式\n",
    "        * AMQP模式，AMQP实现了事务机制\n",
    "        * confirm模式\n",
    "        \n",
    "###### AMQP 事务机制\n",
    "* txSelect 用于将当前channel设置为transaction模式\n",
    "* txCommit 用于提交事务\n",
    "* txRollback 用于回滚事务\n",
    "\n",
    "* publisher\n",
    "```java\n",
    "try {\n",
    "    channel.txSelect();     //选择Transaction模式\n",
    "    channel.basicPublish(\"\", \"hello\", null, \"Hello World!\");\n",
    "    channel.txCommit();       //顺利无异常执行结束，则commit\n",
    "} catch (Exception e) {\n",
    "    cannel.txRollback();      // 有异常则rollback\n",
    "}\n",
    "```\n",
    "\n",
    "* 缺点\n",
    "    * 网络IO高，一个操作，需要select，commit，rollback 2-3次IO\n",
    "    * 降低了吞吐量\n",
    "           \n",
    "###### confirm 机制\n",
    "* 进入confirm模式之后，每一条消息都会有一个ID\n",
    "* broker在确认消息进入队列后，会返回给生产者一个ACK + message ID\n",
    "* confirm模式下，是**异步**的\n",
    "    * Nack, negetive ack, 如果MQ出异常崩溃，则会给producer返回一个Nack, 生产者也有回掉函数来处理\n",
    "* 编程模式\n",
    "    * 普通模式 Blocking waitForConfirms()\n",
    "    * 批量发 Blocking waitForConfirms()\n",
    "    * Async, 给broker一个callback\n",
    "\n",
    "* 普通模式\n",
    "\n",
    "```java\n",
    "channel.confirm.Select();      //生产者将channel设置为confirm模式\n",
    "\n",
    "channel.basicPublish(\"\", \"hello\", null, \"Hello World!\");\n",
    "\n",
    "if(!channel.waitForConfirms()){         // Blocking等待confirm\n",
    "    System.out.println(\"Message send failure\");\n",
    "}else{\n",
    "    System.out.println(\"Message send success\");\n",
    "}\n",
    "```\n",
    "\n",
    "* 批量模式\n",
    "\n",
    "```java\n",
    "channel.confirm.Select();      //生产者将channel设置为confirm模式\n",
    "\n",
    "for(int i=0; i<10; i++){\n",
    "    channel.basicPublish(\"\", \"hello\", null, \"Hello World!\");\n",
    "}\n",
    "\n",
    "if(!channel.waitForConfirms()){         // Blocking等待confirm\n",
    "    System.out.println(\"Message send failure\");\n",
    "}else{\n",
    "    System.out.println(\"Message send success\");\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "#### 4.2.1 简单队列 Simple Queue\n",
    "##### 模型\n",
    "![HBASE Map Reduce](img/rabbitmq_1.png)\n",
    "\n",
    "##### 编程\n",
    "    * 首先获取和消息中间件，MQ，的一个链接\n",
    "    * 创建channel通道\n",
    "\n",
    "###### producer\n",
    "```python\n",
    "connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\n",
    "channel = connection.channel()\n",
    "\n",
    "channel.queue_declare(queue='hello')\n",
    "\n",
    "channel.basic_publish(exchange='',\n",
    "                      routing_key='hello',\n",
    "                      body='Hello World!')\n",
    "print(\" [x] Sent 'Hello World!'\")\n",
    "channel.close()\n",
    "```\n",
    "\n",
    "###### consumer\n",
    "\n",
    "```python\n",
    "channel.queue_declare(queue='hello')\n",
    "\n",
    "def callback(ch, method, properties, body):\n",
    "    print(\" [x] Received %r\" % body)\n",
    "    \n",
    "channel.basic_consume(queue='hello',\n",
    "                      auto_ack=True,\n",
    "                      on_message_callback=callback)\n",
    "\n",
    "print(' [*] Waiting for messages. To exit press CTRL+C')\n",
    "channel.start_consuming()\n",
    "```\n",
    "\n",
    "\n",
    "###### 不足\n",
    "* producer一一对应consumer，耦合度高\n",
    "    * 如果多个consumer对应一个producer，不行\n",
    "* 如果队列名变更\n",
    "    * 生产者，消费者都得更改\n",
    "\n",
    "#### 4.2.2 work queue 工作队列\n",
    "一个producer对应多个consumer\n",
    "##### 模型\n",
    "![HBASE Map Reduce](img/rabbitmq_2.png)\n",
    "    * 原因\n",
    "        * 一般生产者产生message毫不费力\n",
    "        * 而消费者拿到message之后是需要处理，一般较慢\n",
    "        * 一对一的关系，会造成queue的积压\n",
    "        \n",
    "##### 程序\n",
    "\n",
    "###### producer\n",
    "```python\n",
    "channel.queue_declare(queue='task_queue', durable=True)  # 让消息可以被持久化\n",
    "\n",
    "message = ' '.join(sys.argv[1:]) or \"Hello World!\"\n",
    "channel.basic_publish(\n",
    "    exchange='',\n",
    "    routing_key='task_queue',\n",
    "    body=message,\n",
    "    properties=pika.BasicProperties(\n",
    "        delivery_mode=2,  # make message persistent!\n",
    "    ))\n",
    "print(\" [x] Sent %r\" % message)\n",
    "connection.close()\n",
    "```\n",
    "\n",
    "###### consumer\n",
    "```python\n",
    "channel.queue_declare(queue='task_queue', durable=True)\n",
    "print(' [*] Waiting for messages. To exit press CTRL+C')\n",
    "\n",
    "\n",
    "def callback(ch, method, properties, body):\n",
    "    print(\" [x] Received %r\" % body)\n",
    "    time.sleep(body.count(b'.'))\n",
    "    print(\" [x] Done\")\n",
    "    ch.basic_ack(delivery_tag=method.delivery_tag)\n",
    "\n",
    "\n",
    "channel.basic_qos(prefetch_count=1)   # 确认消息分发方式：公平分发\n",
    "channel.basic_consume(queue='task_queue', on_message_callback=callback)\n",
    "\n",
    "channel.start_consuming()\n",
    "```\n",
    "###### consumer之间消息怎样dispatch\n",
    "    * round-robin 轮询分发 - default\n",
    "        * By default, RabbitMQ will send each message to the next consumer, in sequence.\n",
    "        * On average every consumer will get the same number of messages. \n",
    "        * This way of distributing messages is called round-robin.\n",
    "    * fair dispatch 公平. basic_qos\n",
    "        * 限制消费者每次只处理一条消息，直到消费者ack，MQ不会继续给该consumer分发消息\n",
    "        * 要使用fair dispatch必须disable auto ack，不然没效果嘛\n",
    "\n",
    "\n",
    "```shell\n",
    "python worker.py  ## start one consumer\n",
    "\n",
    "python worker.py ## start another\n",
    "\n",
    "# default round robin, 也可以使用fair dispatch，把消息在两个consumer之间分发\n",
    "```\n",
    "\n",
    "#### 4.2.3 publish/subscribe\n",
    "##### 模型\n",
    "![HBASE Map Reduce](img/rabbitmq_3.png)\n",
    "\n",
    "* 一个Producer，多个consumer\n",
    "* 每个consumer都有自己的队列\n",
    "* producer没有直接把消息发送到队列，而是发给交换机，exhange\n",
    "* 每个队列都要绑定到exchange，才能接受消息\n",
    "\n",
    "##### 代码\n",
    "\n",
    "###### producer\n",
    "\n",
    "```python\n",
    "# 绑定到exchange上，而不是把channel直接连接到queue\n",
    "channel.exchange_declare(exchange='logs', exchange_type='fanout') \n",
    "\n",
    "message = ' '.join(sys.argv[1:]) or \"info: Hello World!\"\n",
    "channel.basic_publish(exchange='logs', routing_key='', body=message)\n",
    "print(\" [x] Sent %r\" % message)\n",
    "connection.close()\n",
    "```\n",
    "\n",
    "###### consumer\n",
    "\n",
    "```python\n",
    "channel.exchange_declare(exchange='logs', exchange_type='fanout')\n",
    "\n",
    "# declare自己的queue上\n",
    "result = channel.queue_declare('', exclusive=True)\n",
    "queue_name = result.method.queue\n",
    "\n",
    "# 把queue bind到exchange上\n",
    "channel.queue_bind(exchange='logs', queue=queue_name)\n",
    "\n",
    "print(' [*] Waiting for logs. To exit press CTRL+C')\n",
    "\n",
    "def callback(ch, method, properties, body):\n",
    "    print(\" [x] %r\" % body)\n",
    "\n",
    "channel.basic_consume(\n",
    "    queue=queue_name, on_message_callback=callback, auto_ack=True)\n",
    "\n",
    "channel.start_consuming()\n",
    "```\n",
    "\n",
    "#### 4.2.4 routing\n",
    "##### 模型\n",
    "![HBASE Map Reduce](img/rabbitmq_4.png)\n",
    "\n",
    "\n",
    "###### producer\n",
    "\n",
    "```python\n",
    "# exhange 设置为direct, channel绑定到exchange\n",
    "channel.exchange_declare(exchange='direct_logs', exchange_type='direct')\n",
    "\n",
    "severity = sys.argv[1] if len(sys.argv) > 1 else 'info'\n",
    "message = ' '.join(sys.argv[2:]) or 'Hello World!'\n",
    "channel.basic_publish(\n",
    "    exchange='direct_logs', routing_key=severity, body=message)\n",
    "print(\" [x] Sent %r:%r\" % (severity, message))\n",
    "connection.close()\n",
    "```\n",
    "\n",
    "###### consumer\n",
    "\n",
    "```python\n",
    "channel.exchange_declare(exchange='direct_logs', exchange_type='direct')\n",
    "\n",
    "result = channel.queue_declare('', exclusive=True)\n",
    "queue_name = result.method.queue\n",
    "\n",
    "severities = [\"info\", \"warning\", \"error\"]\n",
    "\n",
    "# 需要指定routing_key, 绑定三个routing key到该队列\n",
    "for severity in severities:\n",
    "    channel.queue_bind(\n",
    "        exchange='direct_logs', queue=queue_name, routing_key=severity)\n",
    "\n",
    "print(' [*] Waiting for logs. To exit press CTRL+C')\n",
    "\n",
    "\n",
    "def callback(ch, method, properties, body):\n",
    "    print(\" [x] %r:%r\" % (method.routing_key, body))\n",
    "\n",
    "\n",
    "channel.basic_consume(\n",
    "    queue=queue_name, on_message_callback=callback, auto_ack=True)\n",
    "\n",
    "channel.start_consuming()\n",
    "```\n",
    "\n",
    "#### 4.2.5 Topics\n",
    "##### 模型\n",
    "![HBASE Map Reduce](img/rabbitmq_5.png)\n",
    "\n",
    "* 类似于routing，不过时key matching 支持通配符\n",
    "\n",
    "\n",
    "#### 4.2.6 RPC\n",
    "##### 模型\n",
    "![HBASE Map Reduce](img/rabbitmq_6.png)\n",
    "###### server\n",
    "```python\n",
    "connection = pika.BlockingConnection(\n",
    "    pika.ConnectionParameters(host='localhost'))\n",
    "\n",
    "channel = connection.channel()\n",
    "\n",
    "channel.queue_declare(queue='rpc_queue')\n",
    "\n",
    "def fib(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n - 1) + fib(n - 2)\n",
    "\n",
    "def on_request(ch, method, props, body):\n",
    "    n = int(body)\n",
    "\n",
    "    print(\" [.] fib(%s)\" % n)\n",
    "    response = fib(n)\n",
    "\n",
    "    ch.basic_publish(exchange='',\n",
    "                     routing_key=props.reply_to,    # reply is direct mode, send to the requested client\n",
    "                     properties=pika.BasicProperties(correlation_id = \\\n",
    "                                                         props.correlation_id),\n",
    "                     body=str(response))\n",
    "    ch.basic_ack(delivery_tag=method.delivery_tag)\n",
    "\n",
    "channel.basic_qos(prefetch_count=1)\n",
    "channel.basic_consume(queue='rpc_queue', on_message_callback=on_request)\n",
    "\n",
    "print(\" [x] Awaiting RPC requests\")\n",
    "channel.start_consuming()\n",
    "```\n",
    "###### client\n",
    "```python\n",
    "class FibonacciRpcClient(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.connection = pika.BlockingConnection(\n",
    "            pika.ConnectionParameters(host='localhost'))\n",
    "\n",
    "        self.channel = self.connection.channel()\n",
    "\n",
    "        result = self.channel.queue_declare('', exclusive=True)\n",
    "        self.callback_queue = result.method.queue\n",
    "\n",
    "        self.channel.basic_consume(\n",
    "            queue=self.callback_queue,\n",
    "            on_message_callback=self.on_response,\n",
    "            auto_ack=True)\n",
    "\n",
    "    def on_response(self, ch, method, props, body):\n",
    "        if self.corr_id == props.correlation_id:\n",
    "            self.response = body\n",
    "\n",
    "    def call(self, n):\n",
    "        self.response = None\n",
    "        self.corr_id = str(uuid.uuid4())\n",
    "        self.channel.basic_publish(\n",
    "            exchange='',\n",
    "            routing_key='rpc_queue',\n",
    "            # in the request set a correlation_id, so server know who to send to\n",
    "            properties=pika.BasicProperties(\n",
    "                reply_to=self.callback_queue,\n",
    "                correlation_id=self.corr_id,               \n",
    "            ),\n",
    "            body=str(n))\n",
    "        while self.response is None:\n",
    "            self.connection.process_data_events()\n",
    "        return int(self.response)\n",
    "\n",
    "\n",
    "fibonacci_rpc = FibonacciRpcClient()\n",
    "\n",
    "print(\" [x] Requesting fib(30)\")\n",
    "response = fibonacci_rpc.call(30)\n",
    "print(\" [.] Got %r\" % response)\n",
    "```\n",
    "\n",
    "### 高可用\n",
    "* 集群\n",
    "\n",
    "### 安全\n",
    "* SSL连接"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
